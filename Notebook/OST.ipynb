{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Random Parameter Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def GenRandParaTable(number, **paras):\n",
    "    with open(\"para_table.txt\",\"w\") as f:\n",
    "        f.truncate()\n",
    "    with open(\"para_table.txt\",\"a\") as f:\n",
    "        for key in paras.keys():\n",
    "            f.write(key+' ')\n",
    "        f.write('\\n')\n",
    "        for i in range(number):\n",
    "            for r in paras.values():\n",
    "                f.write(str(round((r[1]-r[0])*np.random.rand()+r[0], 2))+' ')\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import shutil \n",
    "import sqlite3\n",
    "import re\n",
    "\n",
    "def DataPreprocess():\n",
    "    shutil.copyfile('db.parmap','parmap.db') #copy and rename\n",
    "\n",
    "    with sqlite3.connect('parmap.db') as con:\n",
    "        ParaList = pd.read_sql(\"SELECT * FROM ParaList\", con=con)\n",
    "        ParaCombinations = pd.read_sql(\"SELECT * FROM ParaCombinations\", con=con)\n",
    "    ParaCombinations.columns = ['combi_id']+ParaList['name'].tolist()\n",
    "    \n",
    "    ColumnIndex = []\n",
    "    skip = 0\n",
    "    with open('1.txt') as txtData:\n",
    "        lines = txtData.readlines()\n",
    "        for line in lines:\n",
    "            if ((line.find('run') != -1) or (line.find('--') != -1) or line == '\\n'):\n",
    "                if skip == 2:\n",
    "                    break\n",
    "                skip += 1\n",
    "                continue\n",
    "            ColumnIndex.append(np.float64(line.split()[0]))\n",
    "    RowIndex = []\n",
    "    with open('1.txt') as txtData:\n",
    "        lines = txtData.readlines()\n",
    "        for line in lines:\n",
    "            if line.find('run') != -1:\n",
    "                line = re.sub(\"\\D\",'',line)\n",
    "                RowIndex.append(int(line))\n",
    "    LabelMatrix = np.zeros((len(RowIndex)* len(ColumnIndex)))\n",
    "    LabelMatrix.shape\n",
    "    i = 0\n",
    "    with open('1.txt') as txtData:\n",
    "        lines = txtData.readlines()\n",
    "        for line in lines:\n",
    "            if ((line.find('run') == -1) and (line.find('--') == -1) and line != '\\n'):\n",
    "                LabelMatrix[i] = np.float64(line.split()[1])\n",
    "                i += 1\n",
    "    LabelMatrix = LabelMatrix.reshape((len(RowIndex),len(ColumnIndex)))\n",
    "    label = pd.DataFrame(LabelMatrix, RowIndex, ColumnIndex)\n",
    "    \n",
    "    data = pd.DataFrame(np.zeros((len(RowIndex), len(ParaList['name']))),                       RowIndex, ParaList['name'])\n",
    "    \n",
    "    for i in RowIndex:\n",
    "        for j, row in ParaCombinations.iterrows():\n",
    "            if i == row['combi_id']:\n",
    "                data.loc[i] = row\n",
    "                break\n",
    "    for col in data.columns:\n",
    "        data_temp = data.loc[RowIndex[0], col]\n",
    "        for row in RowIndex:\n",
    "            if data_temp != data.loc[row, col]:\n",
    "                break\n",
    "            if row == RowIndex[-1]:\n",
    "                del data[col]\n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alogorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import progressbar\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def Select_Best_SVR_Model(data, label, degree, window, p_bar):\n",
    "    data_train, data_test, label_train, label_test = train_test_split(data, label, test_size=0.2, random_state=16)\n",
    "    \n",
    "    instances = label_train.columns.size\n",
    "    Estimators = []\n",
    "    map = [1,2,3,4,6]\n",
    "    degree = map[degree-1]\n",
    "\n",
    "    C_dft = 100\n",
    "    C_i = 10*int(10/degree)\n",
    "    C = list(-np.array(range(0,C_dft,C_i))+C_dft)+[C_dft]+list(np.array(range(0,C_dft,C_i))+C_dft)\n",
    "    C = list(set(C))\n",
    "    ga_dft = 10\n",
    "    ga_i = int(10/degree)\n",
    "    gamma = list(-np.array(range(0,ga_dft,ga_i))+ga_dft)+[ga_dft]+list(np.array(range(0,ga_dft,ga_i))+ga_dft)\n",
    "    gamma = list(set(gamma))\n",
    "    \n",
    "    progress = progressbar.ProgressBar(redirect_stdout = True)\n",
    "    progress.start(instances)\n",
    "    p_bar['maximum'] = instances\n",
    "    p_bar['value'] = 0\n",
    "    svr_paras = {'kernel':['rbf'], 'C': C, 'gamma': gamma}\n",
    "    \n",
    "    ##---Calculate estimators---##\n",
    "    for i in range(instances):\n",
    "        grid_search_cv = GridSearchCV(SVR(), svr_paras, n_jobs=1, verbose=0)\n",
    "        grid_search_cv.fit(data_train, label_train.iloc[:,i])\n",
    "        Estimators.append(grid_search_cv.best_estimator_)\n",
    "        progress.update(i+1)\n",
    "        p_bar['value']+=1\n",
    "        window.update()\n",
    "    progress.finish()\n",
    "\n",
    "    ##---Calculate MSE---##\n",
    "    data_pred = np.zeros_like(label_test)\n",
    "    i=0\n",
    "    for estimator in Estimators:\n",
    "        data_pred[:,i] = estimator.predict(data_test)\n",
    "        i=i+1\n",
    "    MSE = mean_squared_error(label_test, data_pred)\n",
    "    return MSE, Estimators\n",
    "\n",
    "def SVR_predict(estimators, data):  # data.type = list\n",
    "    result = []\n",
    "    data = np.array(data).reshape(1,-1)\n",
    "    for estimator in estimators:\n",
    "        result.append(estimator.predict(data))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* K-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def Select_Best_KNN_Model(data, label, p_bar):\n",
    "    p_bar['maximum'] = 1\n",
    "    p_bar['value'] = 0\n",
    "    \n",
    "    knn_paras = {'n_neighbors':[2,3,4,5,6,7,8,9,10]}\n",
    "    \n",
    "    grid_search_cv = GridSearchCV(KNeighborsRegressor(), knn_paras,scoring='neg_mean_squared_error', n_jobs=1)\n",
    "    grid_search_cv.fit(data,label)\n",
    "    estimator = grid_search_cv.best_estimator_\n",
    "    \n",
    "    MSE = -grid_search_cv.best_score_\n",
    "    p_bar['value']+=1\n",
    "    \n",
    "    return MSE,estimator\n",
    "\n",
    "def KNN_predict(estimator, data):\n",
    "    data = np.array(data).reshape(1,-1)\n",
    "    return estimator.predict(data).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def Select_Best_RF_Model(data, label, p_bar):\n",
    "    p_bar['maximum'] = 1\n",
    "    p_bar['value'] = 0\n",
    "    \n",
    "    rf_paras = {'n_estimators':[200]}\n",
    "    \n",
    "    grid_search_cv = GridSearchCV(RandomForestRegressor(), rf_paras,scoring='neg_mean_squared_error', n_jobs=1)\n",
    "    grid_search_cv.fit(data,label)\n",
    "    estimator = grid_search_cv.best_estimator_\n",
    "    \n",
    "    MSE = -grid_search_cv.best_score_\n",
    "    p_bar['value']+=1\n",
    "    \n",
    "    return MSE,estimator\n",
    "\n",
    "def RF_predict(estimator, data):\n",
    "    data = np.array(data).reshape(1,-1)\n",
    "    return estimator.predict(data).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAINLOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "import matplotlib\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "from matplotlib.figure import Figure\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "SVR_estimators = [] #测试用，避免被删除\n",
    "KNN_estimator = []\n",
    "RF_estimator = []\n",
    "data = []\n",
    "label = []\n",
    "MSE = 0\n",
    "neigh = []\n",
    "x_min,x_max,y_min,y_max = 0,0,0,0  #plot axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###---------------------------------------------------------------------------------------------------------------------------------------###\n",
    "window = tk.Tk()\n",
    "window.title('ULTIMATE SIMULATION TOOL')\n",
    "window.geometry('1000x500')\n",
    "\n",
    "###-----PREDEFINE-----###\n",
    "font_step = ('Georgia', 14, 'italic')\n",
    "font_argu = ('Microsoft Yahei', 12)\n",
    "font_help = ('Microsoft Yahei', 10)\n",
    "First_Train = True\n",
    "\n",
    "scales = []\n",
    "\n",
    "###-----PROGRESS_BAR-----###\n",
    "p1 = ttk.Progressbar(window, length=350, mode=\"determinate\", orient='horizontal')  \n",
    "p1.place(x=600, y=380) \n",
    "\n",
    "###-----STEP 1-----###\n",
    "s1_l1_text = 'STEP 1'\n",
    "s1_l1 = tk.Label(window, text=s1_l1_text,font=font_step,bg='lightgreen').place(x=80, y=10)\n",
    "s1_l2_text = '<终极仿真工具>\\n第一次使用请根据\\nREADME.md\\n文件指引操作- -'\n",
    "s1_l2 = tk.Label(window, text=s1_l2_text,font=font_argu,justify=tk.CENTER).place(x=40, y=45)\n",
    "\n",
    "###-----STEP 2-----###\n",
    "s2_l1_text = 'STEP 2'\n",
    "s2_l1 = tk.Label(window, text=s2_l1_text,font=font_step,bg='lightgreen').place(x=80, y=150)\n",
    "s2_l2_text = '<生成随机参数表>'\n",
    "s2_l2 = tk.Label(window, text=s2_l2_text,font=font_argu,justify=tk.LEFT).place(x=45, y=185)\n",
    "s2_l3_text = '仿真次数：'\n",
    "s2_l3 = tk.Label(window, text=s2_l3_text,font=font_argu,justify=tk.LEFT).place(x=10, y=220)\n",
    "s2_l4_text = '参数范围：'\n",
    "s2_l4 = tk.Label(window, text=s2_l4_text,font=font_argu,justify=tk.LEFT).place(x=10, y=250)\n",
    "s2_l5_text = '参数范围输入格式：\\n参数名1=[min,max],参数名2=[...'\n",
    "s2_l5 = tk.Label(window, text=s2_l5_text,font=font_help,\n",
    "                 justify=tk.LEFT).place(x=15, y=275)\n",
    "s2_l6_text = 'CST-->parameter sweep-->import-->\\ndefine multiple sequences-->\\n选择生成的para_table.txt文件-->ok'\n",
    "s2_l6 = tk.Label(window, text=s2_l6_text,font=font_help,\n",
    "                 justify=tk.LEFT).place(x=15, y=350)\n",
    "s2_l7_text = '在点击start仿真之前,必须把需要观察的结\\n果保存在template based postprocessing中\\n,即使是S参数也需要用此方法复制一份结果.'\n",
    "s2_l7 = tk.Label(window, text=s2_l7_text,font=font_help,\n",
    "                 justify=tk.LEFT,bg='yellow').place(x=15, y=415)\n",
    "s2_var1 = tk.StringVar()\n",
    "s2_l8_text = tk.Label(window, textvariable=s2_var1,font=font_argu,bg='yellow',width=6).place(x=165, y=320)\n",
    "\n",
    "s2_e1 = ttk.Entry(window,width=5)\n",
    "s2_e1.place(x=100, y=223)\n",
    "s2_e1.insert(tk.END,'250')\n",
    "s2_e2 = ttk.Entry(window)\n",
    "s2_e2.place(x=100, y=253)\n",
    "s2_e2.insert(tk.END,'h2=[0.8,1],h3=[0.5,1],t1=[0.7,1.2],t2=[1.1,1.9]')\n",
    "    \n",
    "def s2_b1_func():\n",
    "    try:\n",
    "        var1 = int(s2_e1.get())\n",
    "        var2 = s2_e2.get()\n",
    "        eval('GenRandParaTable(var1, '+var2+')')\n",
    "        with open('temp_paras.txt','w') as f:\n",
    "            f.write(var2)\n",
    "    except:\n",
    "        s2_var1.set('失败！')\n",
    "    else:\n",
    "        s2_var1.set('完成！')\n",
    "    \n",
    "s2_b1 = ttk.Button(window,text=\"生成\",width=10,command=s2_b1_func).place(x=80,y=320)\n",
    "\n",
    "###-----STEP 3-----###\n",
    "s3_l1_text = 'STEP 3'\n",
    "s3_l1 = tk.Label(window, text=s3_l1_text,font=font_step,bg='lightgreen').place(x=300, y=10)\n",
    "s3_l2_text = '<导出结果- ->'\n",
    "s3_l2 = tk.Label(window, text=s3_l2_text,font=font_argu).place(x=290, y=40)\n",
    "s3_l3_text = 'CST-->\\nNavigation Tree-->\\nTables-->\\n选择需要训练的结果-->\\nPost Processing-->\\nImport/Export-->\\nPlot Data(ASCII)-->\\n命名为< 1.txt >'\n",
    "s3_l3 = tk.Label(window, text=s3_l3_text,font=font_help,justify=tk.LEFT).place(x=260, y=65)\n",
    "s3_l4_text = '进入STEP 4前确保1.txt与\\n此文件处于同一根目录下！'\n",
    "s3_l4 = tk.Label(window, text=s3_l4_text,font=font_help,\n",
    "                 justify=tk.LEFT,bg='yellow').place(x=260, y=220)\n",
    "s3_l5_text = 'STEP 4'\n",
    "s3_l5 = tk.Label(window, text=s3_l5_text,font=font_step,bg='lightgreen').place(x=300, y=270)\n",
    "s3_l6_text = '<选择一个算法>'\n",
    "s3_l6 = tk.Label(window, text=s3_l6_text,font=font_argu).place(x=290, y=300)\n",
    "s3_var3 = tk.StringVar()  #MSE\n",
    "s3_var3.set('MSE:')\n",
    "s3_l7 = tk.Label(window, textvariable=s3_var3,font=font_argu).place(x=600, y=350)\n",
    "s3_l8_text = '<蓝色：预测曲线><橙色：最邻近实际曲线>'\n",
    "s3_l8 = tk.Label(window, text=s3_l8_text,font=font_argu).place(x=600, y=410)\n",
    "s3_var4 = tk.StringVar()  #nearest neighbor\n",
    "s3_var4.set('最邻近参数：')\n",
    "s3_l9 = tk.Label(window, textvariable=s3_var4,font=font_argu).place(x=600, y=435)\n",
    "\n",
    "s3_var1 = tk.StringVar()  #执行情况信息\n",
    "s3_l10 = tk.Label(window, textvariable=s3_var1,font=font_argu,bg='yellow',width=8).place(x=350, y=400)\n",
    "\n",
    "s3_var2 = tk.StringVar()  #算法选择信息\n",
    "s3_var2.set('KNN') #默认值\n",
    "\n",
    "s3_c1 = ttk.Combobox(window,value=(1,2,3,4,5),width=2,state='readonly')\n",
    "s3_c1.place(x=370,y=370)\n",
    "s3_c1.current(0)\n",
    "\n",
    "s3_r1 = ttk.Radiobutton(window, text='KNN',variable=s3_var2 ,value='KNN').place(x=300,y=330)\n",
    "s3_r2 = ttk.Radiobutton(window, text='SVM',variable=s3_var2 ,value='SVM').place(x=300,y=370)\n",
    "s3_r3 = ttk.Radiobutton(window, text='RF',variable=s3_var2 ,value='RF').place(x=300,y=350)\n",
    "\n",
    "image = Figure(figsize=(5,4), dpi=80)\n",
    "plot = image.add_subplot(111)\n",
    "plot.plot([])\n",
    "canvas =FigureCanvasTkAgg(image, master=window)\n",
    "canvas.draw()\n",
    "canvas.get_tk_widget().place(x=590,y=20)\n",
    "def plot_data(useless):\n",
    "    one_data = []\n",
    "    for scaler in scales:\n",
    "        one_data.append(scaler.get())\n",
    "    if s3_var2.get() == 'SVM':\n",
    "        result = SVR_predict(SVR_estimators, one_data)\n",
    "    elif s3_var2.get() == 'KNN':\n",
    "        result = KNN_predict(KNN_estimator, one_data)\n",
    "    elif s3_var2.get() == 'RF':\n",
    "        result = RF_predict(RF_estimator, one_data)\n",
    "\n",
    "    plot.clear()\n",
    "    plot.plot(label.columns,result,color='blue')\n",
    "    nearest_neigh = neigh.kneighbors([one_data],return_distance=False).item()\n",
    "    s3_var4.set('最邻近参数:'+str(data.iloc[nearest_neigh,:].tolist()))\n",
    "    plot.plot(label.columns,label.iloc[nearest_neigh,:].tolist(),color='orange')\n",
    "    if s3_var5.get() == True:\n",
    "        plot.axis([x_min,x_max,y_min,y_max])\n",
    "    canvas.draw()\n",
    "    \n",
    "def generate_scale(data):\n",
    "    global scales\n",
    "    min_sers = pd.Series(data.min()).to_dict()\n",
    "    max_sers = pd.Series(data.max()).to_dict()\n",
    "    i=0\n",
    "    for key,min_v,max_v in zip(min_sers.keys(),min_sers.values(),max_sers.values()):\n",
    "        scales.append(tk.Scale(window, label=key, from_=min_v, to=max_v, orient=tk.HORIZONTAL,\n",
    "                     length=120, showvalue=1, resolution=0.01,command=plot_data))\n",
    "        scales[i].place(x=450,y=i*59)\n",
    "        i+=1\n",
    "\n",
    "def s3_b1_func():\n",
    "    global data, label, MSE, SVR_estimators,KNN_estimator,RF_estimator,\\\n",
    "    First_Train, neigh,x_min,x_max,y_min,y_max\n",
    "    \n",
    "    s3_var1.set('导入中。。')\n",
    "    window.update()\n",
    "    if First_Train:\n",
    "        data,label = DataPreprocess()\n",
    "        x_min = label.columns.min()\n",
    "        x_max = label.columns.max()\n",
    "        y_min = label.min().min()\n",
    "        y_max = label.max().max()\n",
    "        neigh = NearestNeighbors(n_neighbors=1)\n",
    "        neigh.fit(data)\n",
    "    \n",
    "    s3_var1.set('计算中。。')\n",
    "    window.update()\n",
    "    if s3_var2.get() == 'SVM':\n",
    "        MSE,SVR_estimators = Select_Best_SVR_Model(data,label,int(s3_c1.get()),window,p1)\n",
    "    elif s3_var2.get() == 'KNN':\n",
    "        MSE,KNN_estimator = Select_Best_KNN_Model(data, label, p1)\n",
    "    elif s3_var2.get() == 'RF':\n",
    "        MSE,RF_estimator = Select_Best_RF_Model(data, label, p1)\n",
    "        \n",
    "    s3_var1.set('完成！')\n",
    "    window.update()\n",
    "    \n",
    "    s3_var3.set('MSE:'+str(MSE))\n",
    "    #generate scales\n",
    "    if First_Train:\n",
    "        generate_scale(data)\n",
    "        First_Train = False\n",
    "    \n",
    "s3_b1 = ttk.Button(window,text=\"训练\",width=5,command=s3_b1_func).place(x=300,y=400)\n",
    "\n",
    "s3_var5 = tk.BooleanVar()\n",
    "s3_ch1 = ttk.Checkbutton(window, text='固定y轴',variable = s3_var5)\n",
    "s3_ch1.place(x=900, y=350)\n",
    "\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
